{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLuILeV5UL2z",
        "outputId": "5a4a13f9-b7a5-473e-d14a-d625898fd5d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate -U -q\n",
        "!pip install git+https://github.com/Bots-Avatar/ExplainitAll -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "from explainitall.fast_tuning.trainers.HMMTrainer import GPT2HMMDataProcessor\n",
        "from explainitall.fast_tuning.generators import GeneratorWithExpert\n",
        "from explainitall.fast_tuning.generators import MCExpert\n",
        "from explainitall.fast_tuning.generators import MCModel\n",
        "from explainitall.fast_tuning.trainers.ProjectionTrainer import GPTProjectionTrainer\n",
        "from explainitall.fast_tuning.ExpertBase import ExpertModel\n",
        "import numpy as np\n",
        "import torch\n",
        "import re"
      ],
      "metadata": {
        "id": "9K1hkj28Uz69"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Датасет\n",
        "Создание и сохранение датасета (полстранички из Википедии)\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "J8_5_VjhYwWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = '''Электро́нная лампа, радиолампа — электровакуумный прибор (точнее, вакуумный электронный прибор), работающий за счёт управления интенсивностью потока электронов, движущихся в вакууме или разрежённом газе между электродами[1].\n",
        "Радиолампы массово использовались в XX веке как основные элементы радиоаппаратуры, так как позволяют выпрямлять ток, усиливать, генерировать электрические сигналы и т. п. С появлением полупроводниковых приборов (диодов, транзисторов) радиолампы стали вытесняться из радиоаппаратуры, так как полупроводниковые приборы оказались значительно компактнее и экономичнее. В настоящее время радиолампы встречаются там, где полупроводниковые аналоги получаются дороже или сложнее в изготовлении, например в качестве мощного генератора радиоволн в микроволновой печи используется радиолампа — магнетрон. Также радиолампы традиционно используются в некоторых видах аудиоаппаратуры, позиционируемой как высококачественная (high-end).\n",
        "Электронные лампы, предназначенные для освещения (лампы-вспышки, ксеноновые лампы, ртутные и натриевые лампы), радиолампами не называются и обычно относятся к классу осветительных приборов.\n",
        "Электронно-лучевые приборы основаны на тех же принципах, что и радиолампы, но, помимо управления интенсивностью электронного потока, также управляют распределением электронов в пространстве и потому выделяются в отдельную группу. Также в отдельную группу выделяют СВЧ-электровакуумные приборы, основанные на взаимодействии электронного потока с электромагнитным полем в таких приборах как магнетрон, клистрон и др.\n",
        "Самая простая радиолампа имеет колбу, внутри которой размещены два электрода — катод и анод. Катод разогревается от источника тока до температуры, когда из него вследствие термоэлектронной эмиссии могут вылетать электроны, и свободно перемещаться внутри вакуума колбы. Электроны имеют отрицательный заряд, и если на второй электрод, анод, будет подан положительный потенциал, электроны устремятся к аноду, попадут в него и создадут ток в цепи анод-катод. Если на анод подать отрицательный потенциал, то электроны имея одноимённый заряд будут отталкиваться от анода, и ток в цепи протекать не будет. Такая простая радиолампа называется кенотрон и пригодна для выпрямления переменного тока в постоянный ток, так как проводит ток только в одном направлении.\n",
        "Более сложная радиолампа — триод устроена так же, но имеет ещё и третий электрод — сетку, расположенную между анодом и катодом. Если потенциал на сетке отсутствует, а на аноде потенциал положительный, то все электроны вылетевшие с катода устремляются к аноду и создают ток в цепи анода. Если подать на сетку небольшой отрицательный потенциал, то она своим полем сможет отклонять часть электронов на пути к аноду, тем самым уменьшая ток анода. Чем выше отрицательный потенциал на сетке — тем бо́льшая часть электронов будет отклонена, тем меньше ток анода. Если подать на сетку достаточно большой отрицательный потенциал — то лампа окажется «заперта» — ток в цепи анода прекратится. Такая лампа может работать как усилитель, если подать на сетку слабый электрический сигнал, то он вызовет синхронные изменения тока анода, причем на ощутимо бо́льшие величины.\n",
        "Различные усложнения конструкции лампы — применение катода косвенного накала, введение дополнительных сеток, изменение формы колбы или введение в него небольшого количества газа улучшают одни параметры лампы, ухудшая другие, но основной принцип работы радиолампы не меняется — управление потоком электронов от катода к аноду при помощи электрического поля сеток.\n",
        "Существенным недостатком радиоламп является её размер и необходимость постоянно тратить энергию на поддержание катода в нагретом состоянии (кроме ламп с холодным катодом).\n",
        "Вакуумные электронные лампы с подогревным катодом\n",
        "В результате термоэлектронной эмиссии электроны покидают катод.\n",
        "Под воздействием напряжения между анодом и катодом электроны достигают анода и образуют анодный ток во внешней цепи.\n",
        "С помощью дополнительных электродов (сеток) осуществляется управление электронным потоком путём подачи на эти электроды электрических напряжений.\n",
        "Электронная лампа RCA '808'\n",
        "В вакуумных электронных лампах наличие газа ухудшает характеристики лампы.\n",
        "Газоразрядные электронные лампы\n",
        "В СССР и в России традиционно выделяются в отдельный класс ионных приборов в отличие от вакуумных ламп. Основной ток проводимости в этих устройствах вызван потоком ионов в газе, наполняющем лампу. Ионизация газа может вызываться соударениями атомов или молекул газа с электронами, как и в вакуумных лампах эмиттируемыми накалённым катодом, а может создаваться самоподдерживающимся разрядом в разреженном газе за счёт ускорения ионов электрическим полем. Как правило, такие лампы используются либо в низкочастотных и импульсных генераторах (тиратроны), либо в схемах управляемых выпрямителей, часто с высокими выходными токами — схемы на игнитронах.\n",
        "Типы газоразрядных электронных ламп:\n",
        "неоновая лампа;\n",
        "газоразрядный стабилитрон;\n",
        "ионный разрядник;\n",
        "тиратрон;\n",
        "игнитрон.\n",
        "Неоновая лампа\n",
        "Неоновая лампа — разновидность газоразрядного прибора тлеющего разряда, представляет собой стеклянный баллона в котором располагаются два электрода. Баллон наполнен инертным газом (неоном) при небольшом давлении. Электроды изготавливаются из металла, например никеля, и могут быть различной формы (два цилиндрических, два плоских и др.)\n",
        "Неоновые лампы излучают оранжево-красный свет небольшой интенсивности и используются, в основном, как индикаторные. Неоновую лампу подключают к источнику напряжения последовательно с ограничительным резистором, иначе разряд сразу переходит в дуговой и лампа выходит из строя.\n",
        "Стабилитрон\n",
        "Газоразрядный стабилитрон представляет собой стеклянный баллон, в котором находятся два электрода — катод и анод. Катод имеет форму цилиндра с большой поверхностью, анод — стержень, расположенный вдоль оси катода. Внутренняя поверхность катода активируется. Баллон наполняется аргоном, неоном или смесью газов при давлении в несколько десятков миллиметров ртутного столба. Благодаря большой поверхности катода, напряжение между электродами при значительных изменениях тока тлеющего разряда остается неизменным.\n",
        "Параметрами стабилитрона являются: напряжение зажигания, напряжение горения, минимальный и максимальный ток. Величина напряжения стабилизации зависит от вида газа и материала катода, которым наполнен баллон.\n",
        "Стабилитрон с коронным разрядом\n",
        "Кроме стабилитронов с тлеющим разрядом, описанных выше, существуют стабилитроны с коронным разрядом. Устройство данных стабилитронов схоже со стабилитронами тлеющего разряда. Баллон наполняется водородом при низком давлении. Стабилитроны с коронным разрядом имеют в несколько раз более высокие значения напряжения горения, и позволяют стабилизировать напряжение порядка 300—1000 В и более. Однако ток, проходящий через такой стабилитрон в сотни раз меньше чем у стабилитронов с тлеющим разрядом[2].\n",
        "'''"
      ],
      "metadata": {
        "id": "130YCBYYW4ZU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранение датасета\n",
        "with open('dataset', 'w') as file:\n",
        "    file.write(text_data)"
      ],
      "metadata": {
        "id": "XaJBVU_VYj7A"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Чтение датасета\n",
        "with open('dataset', 'r') as file:\n",
        "  text = file.read()"
      ],
      "metadata": {
        "id": "CQgQjY7DZhjJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Загрузка основной модели\n",
        "\n",
        "Загрузка модели \"rugpt3medium_based_on_gpt2\"."
      ],
      "metadata": {
        "id": "69fO2KfNZ_hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'ai-forever/rugpt3medium_based_on_gpt2'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(path)\n",
        "gpt = GPT2LMHeadModel.from_pretrained(path)\n",
        "gpt.to('cuda')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76xFfzMPXDhr",
        "outputId": "b789611b-e03b-41fa-cae1-84816a8ad16e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GPT2LMHeadModel(\n",
              "  (transformer): GPT2Model(\n",
              "    (wte): Embedding(50257, 1024)\n",
              "    (wpe): Embedding(2048, 1024)\n",
              "    (drop): Dropout(p=0.1, inplace=False)\n",
              "    (h): ModuleList(\n",
              "      (0-23): 24 x GPT2Block(\n",
              "        (ln_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (attn): GPT2Attention(\n",
              "          (c_attn): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
              "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ln_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (mlp): GPT2MLP(\n",
              "          (c_fc): Conv1D()\n",
              "          (c_proj): Conv1D()\n",
              "          (act): NewGELUActivation()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (ln_f): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=50257, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Создание и тестирование эксперта на базе марковской цепи"
      ],
      "metadata": {
        "id": "wAOiAIIWaeEE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = text.replace('\\n', ' ').replace('  ', ' ')\n",
        "hmm_expert_creator = GPT2HMMDataProcessor(tokenizer)\n",
        "tokens = hmm_expert_creator.get_data_1(re.split('\\.|,', text))\n",
        "data = hmm_expert_creator.create_data(tokens)\n",
        "hmm_expert_states = hmm_expert_creator.train(data)"
      ],
      "metadata": {
        "id": "B54XE1fIXQGa"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bias_mask = set(tokens.flatten()) # Маска для смещения (словарь токенов)"
      ],
      "metadata": {
        "id": "vM7XWCP1at5S"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_v = tokenizer.vocab_size\n",
        "mc_model = MCModel.MarkovModel(l_v, data['x_encoder'], data['y_decoder'], model=hmm_expert_states)\n",
        "hmm_expert = MCExpert.MCExpert(mc_model)\n",
        "l_v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNgNIfrGXV41",
        "outputId": "fb5df1d3-ee19-40fc-8111-da305b8a76d1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50257"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Простой(жадный) генератор для эксперта\n",
        "\n",
        "tokens_expert = []\n",
        "\n",
        "for i in range(30):\n",
        "  input_tok = tokens_expert\n",
        "  outp_token = np.argmax(hmm_expert.get_bias(input_tok))\n",
        "  tokens_expert.append(outp_token)\n",
        "\n",
        "tokenizer.decode(tokens_expert)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "O3n-RWceYWag",
        "outputId": "9875c3ca-ddf5-465a-a628-d9e8636318e0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' и если на второй электрод</s><s><s> и если на второй электрод</s><s><s> и если на второй электрод</s><s><s> и если на второй электрод</s>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение слоев проекций основной сети с учетом маски"
      ],
      "metadata": {
        "id": "Yq-S7E0Oa8y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = GPTProjectionTrainer(gpt, tokenizer)\n",
        "trainer.train('dataset',bias_mask, num_train_epochs = 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "RZycJ7ImZyki",
        "outputId": "69a7caad-9a6b-40ab-dcaa-33d0c1de2e30"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [120/120 00:23, Epoch 40/40]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Генерация"
      ],
      "metadata": {
        "id": "j6KS4AnSbR24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.set_variety(bias_mask, 0.1)\n",
        "gpt.to('cuda')\n",
        "\n",
        "input_ids = tokenizer.encode('Электро́нная лампа', return_tensors='pt').to('cuda:0')\n",
        "\n",
        "\n",
        "output_sequences = gpt.generate(\n",
        "    input_ids=input_ids,\n",
        "    max_length=100,\n",
        "    temperature=0.7,\n",
        "    top_k=50,\n",
        "    top_p=0.95,\n",
        "    repetition_penalty=1.2,\n",
        "    do_sample=True,\n",
        "    num_return_sequences=1\n",
        ")\n",
        "\n",
        "generated_text = tokenizer.decode(output_sequences[0], skip_special_tokens=True)\n",
        "\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nBK0c8iaX-q",
        "outputId": "f92a5c7c-ff70-4534-fb50-e9c3a24ac3ac"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Электро́нная лампа, радиолампа — осветительный прибор (точнее, вакуумный электронный прибор), работающий за счёт управления интенсивностью потока электронов, движущихся в вакууме.\n",
            "Радиолокатор\n",
            "Госкомиссия СССР по радиофикации при Совете Министров СССР приняла решение о строительстве в 1955 году первой советской водородной бомбы, получившей условное обозначение «Р-1». В рамках этой программы под руководством С. П. Королёва и М. И. Нед\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация с экспертом\n",
        "start = 'Электро́нная лампа'\n",
        "generator_with_expert = GeneratorWithExpert.GPTGenerator(expert=hmm_expert, model=gpt, tokenizer=tokenizer, device='cuda:0')\n",
        "end = generator_with_expert.Generate(start, expert_w=0.6, max_len=40, num_seq=1, temperature=0.1)[0]\n",
        "\n",
        "print(start + end)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-YtznwaatY1",
        "outputId": "09c671dc-9d66-4081-c5c1-3ec56b8945b7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Электро́нная лампа, радиолампа — электровакуумный прибор (точнее, вакуумный электронный прибор) предназначенный для генерирования электрического тока, проводимости в жидкости, и управления интенсивностью потока электронов в\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT Эксперт"
      ],
      "metadata": {
        "id": "xOPeR0eHePe-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'ai-forever/rugpt3small_based_on_gpt2'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(path)\n",
        "gpt_ex_m = GPT2LMHeadModel.from_pretrained(path)\n",
        "gpt_ex_m = gpt_ex_m.to('cuda')"
      ],
      "metadata": {
        "id": "PhHD5bZpeOIj"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучаем все слои проекции\n",
        "trainer = GPTProjectionTrainer(gpt_ex_m, tokenizer)\n",
        "trainer.train('dataset',bias_mask, num_train_epochs = 60, last_k=12, output_dir='s', variety=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "2m9oKRTQerxp",
        "outputId": "5207ba4b-300f-4ee4-be8c-fa68302b986d"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the 🤗 Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='180' max='180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [180/180 00:18, Epoch 60/60]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание эксперта из gpt\n",
        "\n",
        "class GPTExpert(ExpertModel):\n",
        "\n",
        "      def __init__(self, gpt_ex_m, len_v) -> None:\n",
        "         super().__init__()\n",
        "         self.gpt = gpt_ex_m\n",
        "         self.len_v = len_v\n",
        "\n",
        "      def get_bias(self, tokens):\n",
        "        \"\"\"Вычисление bias из вероятностной модели\"\"\"\n",
        "        tokens_ = torch.tensor([tokens]).to(self.gpt.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          outp = self.gpt(tokens_)\n",
        "        return outp['logits'][0][-1].cpu().detach().numpy()[:self.len_v]"
      ],
      "metadata": {
        "id": "oWC639guftSS"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_expert = GPTExpert(gpt_ex_m, 50257)"
      ],
      "metadata": {
        "id": "aDoIubJNlcaq"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация экспертом\n",
        "t = tokenizer.encode('<s> Неоновая')\n",
        "tokens_expert = t\n",
        "\n",
        "for i in range(30):\n",
        "  outp_token = np.argmax(gpt_expert.get_bias(tokens_expert))\n",
        "  tokens_expert.append(outp_token)\n",
        "\n",
        "tokenizer.decode(tokens_expert)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "K7A-xn5AlZLB",
        "outputId": "171bb91b-a45e-48d0-cb8b-e8430370a8a9"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<s> Неоновая лампа, Неоновая лампа, Неоновая лампа, Неоновая лампа, Неоновая лампа, Неоновая лампа, Неоновая'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = 'Генераторная лампа это '\n",
        "generator_with_expert = GeneratorWithExpert.GPTGenerator(expert=gpt_expert, model=gpt, tokenizer=tokenizer, device='cuda:0')\n",
        "end = generator_with_expert.Generate(start, expert_w=0.5, max_len=40, num_seq=1, temperature=0.1)[0]\n",
        "\n",
        "print(start + end)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOBFREf9l9xQ",
        "outputId": "e52dc36b-f04d-422f-b8df-7311ec1b19be"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Генераторная лампа это \n",
            "Электронно-лучевая лампа, радиолампа — прибор, работающий за счёт управления интенсивностью потока электронов, движущихся в вакууме или разрежённом газе между элект\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Без тюнинга основной GPT"
      ],
      "metadata": {
        "id": "uFCbOaOgvfoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Используем gpt-large без тюнинга, только с экспертом\n",
        "path = 'ai-forever/rugpt3large_based_on_gpt2'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(path)\n",
        "gpt_L = GPT2LMHeadModel.from_pretrained(path)\n",
        "gpt_L.to('cuda')"
      ],
      "metadata": {
        "id": "4aFuHdZhp9my"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = 'Генераторная лампа — это вакуумный прибор'\n",
        "generator_with_expert = GeneratorWithExpert.GPTGenerator(expert=gpt_expert, model=gpt_L, tokenizer=tokenizer, device='cuda:0')\n",
        "end = generator_with_expert.Generate(start, expert_w=0.6, max_len=50, num_seq=1, temperature=0.2, rp=1.5)[0]\n",
        "\n",
        "print(start + end)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QMHOBd0qED-",
        "outputId": "d5d077d6-dd04-4827-e335-e44897b8d43c"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Генераторная лампа — это вакуумный прибор, работающий за счёт подачи на электроды электрических напряжений.\n",
            "Существенным недостатком вакуумных ламп является их размер и необходимость постоянно тратить энергию на поддержание катода в нагретом состоянии.\n",
            "Вакуумные лампы с подогревным катодом\n"
          ]
        }
      ]
    }
  ]
}